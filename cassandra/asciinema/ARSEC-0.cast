{"version": 2, "width": 80, "height": 24, "timestamp": 1537182426, "env": {"SHELL": "/bin/bash", "TERM": "xterm"}}
[0.049262, "o", "\u001b]0;attu7372@ubuntu-2: ~\u0007attu7372@ubuntu-2:~$ "]
[10.605297, "o", "ssh -2 -XY -i $HOME/.ssh/kubeadm-dind-cluster cloud@84.39.39\r9.111"]
[11.654126, "o", "\r\n"]
[11.970798, "o", "Welcome to Ubuntu 16.04.5 LTS (GNU/Linux 4.4.0-135-generic x86_64)\r\n\r\n * Documentation:  https://help.ubuntu.com\r\n * Management:     https://landscape.canonical.com\r\n * Support:        https://ubuntu.com/advantage\r\n\r\n  Get cloud support with Ubuntu Advantage Cloud Guest:\r\n    http://www.ubuntu.com/business/services/cloud\r\n\r\n0 packages can be updated.\r\n0 updates are security updates.\r\n\r\nNew release '18.04.1 LTS' available.\r\nRun 'do-release-upgrade' to upgrade to it.\r\n\r\n\r\n"]
[12.072587, "o", "\u001b]0;~\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~\u001b[0m\r\r\n$ "]
[16.610781, "o", "c"]
[16.711646, "o", "d"]
[16.765727, "o", " "]
[17.391345, "o", "s"]
[17.573514, "o", "r"]
[17.790777, "o", "c"]
[18.12619, "o", "/"]
[18.669496, "o", "k"]
[18.883904, "o", "8s/"]
[20.237653, "o", "c"]
[20.449785, "o", "assandra/"]
[20.871358, "o", "\r\n\u001b]0;~/src/k8s/cassandra\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~/src/k8s/cassandra\u001b[0m\r\r\n$ "]
[23.200792, "o", "k"]
[23.413741, "o", "u"]
[23.629612, "o", "b"]
[23.749836, "o", "e"]
[24.02379, "o", "c"]
[24.328536, "o", "t"]
[24.57337, "o", "l"]
[25.863703, "o", " "]
[26.221369, "o", "g"]
[26.301794, "o", "e"]
[26.445667, "o", "t"]
[26.502393, "o", " "]
[27.500026, "o", "n"]
[27.607831, "o", "o"]
[27.694309, "o", "d"]
[27.78216, "o", "e"]
[27.981276, "o", "s"]
[28.414073, "o", "\r\n"]
[28.523217, "o", "NAME          STATUS    ROLES     AGE       VERSION\r\nkube-master   Ready     master    3d        v1.11.0\r\nkube-node-1   Ready     <none>    3d        v1.11.0\r\nkube-node-2   Ready     <none>    3d        v1.11.0\r\nkube-node-3   Ready     <none>    3d        v1.11.0\r\nkube-node-4   Ready     <none>    3d"]
[28.52686, "o", "        v1.11.0\r\nkube-node-5   Ready     <none>    3d        v1.11.0\r\nkube-node-6   Ready     <none>    3d        v1.11.0\r\nkube-node-7   Ready     <none>    3d        v1.11.0\r\nkube-node-8   Ready     <none>    3d        v1.11.0\r\n\u001b]0;~/src/k8s/cassandra\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~/src/k8s/cassandra\u001b[0m\r\r\n$ "]
[31.578773, "o", "k"]
[31.825722, "o", "u"]
[32.024534, "o", "b"]
[32.181516, "o", "e"]
[33.233007, "o", "c"]
[34.013408, "o", "t"]
[34.173254, "o", "l"]
[34.271305, "o", " "]
[34.902734, "o", "g"]
[35.006385, "o", "e"]
[35.141207, "o", "t"]
[35.20721, "o", " "]
[35.541474, "o", "p"]
[35.72918, "o", "o"]
[36.126081, "o", "d"]
[36.231756, "o", "s"]
[36.276823, "o", " "]
[37.200686, "o", "-"]
[37.325646, "o", "-"]
[38.20481, "o", "a"]
[38.806235, "o", "l"]
[38.934312, "o", "l"]
[40.045255, "o", "-"]
[40.49109, "o", "n"]
[40.613133, "o", "a"]
[41.774278, "o", "m"]
[41.911339, "o", "e"]
[42.232213, "o", "s"]
[42.469247, "o", "p"]
[42.550218, "o", "a"]
[42.785669, "o", "c"]
[42.8777, "o", "e"]
[43.096451, "o", "s"]
[44.392675, "o", "|"]
[44.792839, "o", "m"]
[45.010576, "o", "o"]
[45.101062, "o", "r"]
[45.206437, "o", "e"]
[45.964365, "o", "\r\n"]
[45.967055, "o", "\u001b[?1049h\u001b[?1h\u001b=\r"]
[46.160472, "o", "NAMESPACE     NAME                                    READY     STATUS    RESTAR \bTS   AGE\r\ndefault       kube-apiserver-kube-master              1/1       Running   1      \b     3d\r\ndefault       kube-controller-manager-kube-master     1/1       Running   1      \b     3d\r\ndefault       kube-scheduler-kube-master              1/1       Running   1      \b     3d\r\nkube-system   etcd-kube-master                        1/1       Running   1      \b     3d\r\nkube-system   kube-dns-57f756cc64-5vbx8               3/3       Running   0      \b     3d\r\nkube-system   kube-router-bh97k                       1/1       Running   1      \b     3d\r\nkube-system   kube-router-cctv6                       1/1       Running   1      \b     3d\r\nkube-system   kube-router-ddnjb                       1/1       Running   1      \b     3d\r\nkube-system   kube-router-dm4cd                       1/1       Running   1      \b     3d\r\nkube-system   kube-router-hpcst                       1/1       Running   1      \b     3d\r\nkube-system   kube-rou"]
[46.160702, "o", "ter-jtv44                       1/1       Running   1      \b:\u001b[K"]
[53.711382, "o", "\r\u001b[K     3d\r\nkube-system   kube-router-p57ff                       1/1       Running   1      \b     3d\r\nkube-system   kube-router-s9dg2                       1/1       Running   1      \b     3d\r\nkube-system   kube-router-x87gg                       1/1       Running   1      \b     3d\r\nkube-system   kubernetes-dashboard-54f47d4878-6qf5t   1/1       Running   0      \b     3d\r\n\u001b[7m(END)\u001b[27m\u001b[K"]
[56.288824, "o", "\r\u001b[K \u001b[K:\b:"]
[56.333817, "o", "\u001b[Kq\bq\r\u001b[K\u001b[?1l\u001b>\u001b[?1049l"]
[56.334619, "o", "\u001b]0;~/src/k8s/cassandra\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~/src/k8s/cassandra\u001b[0m\r\r\n$ "]
[57.896963, "o", "m"]
[58.120074, "o", "o"]
[58.246044, "o", "r"]
[58.335354, "o", "e"]
[58.358153, "o", " "]
[59.421044, "o", "p"]
[59.533792, "o", "r"]
[59.68004, "o", "o"]
[59.808337, "o", "perties/"]
[61.088472, "o", "c"]
[61.160275, "o", "l"]
[61.417351, "o", "u"]
[61.503346, "o", "\u0007ster-1.dataCenter-"]
[63.046456, "o", "1"]
[63.454488, "o", "."]
[63.656294, "o", "i"]
[63.774685, "o", "nit.properties "]
[64.651178, "o", "\r\n"]
[64.658373, "o", "\u001b[?1049h\u001b[?1h\u001b=\rnamespace=cassandra\r\npersistentVolume.storageType.cluster-1=local\r\npersistentVolume.dataDirectory.cluster-1=/data/cassandra\r\npersistentVolume.capacity.cluster-1=2Gi\r\nstatefulSet.resource.limit.cpu.cluster-1=500m\r\nstatefulSet.resource.limit.memory.cluster-1=1Gi\r\nstatefulSet.resource.request.cpu.cluster-1=500m\r\nstatefulSet.resource.request.memory.cluster-1=1Gi\r\nstatefulSet.env.maxHeapSize.cluster-1=512M\r\nstatefulSet.env.heapNewSize.cluster-1=100M\r\nstatefulSet.storageCapacity.cluster-1=1Gi\r\nstatefulSet.replicas.cluster-1=10\r\ninstances.cluster-1=2\r\n\r\n# We create a cluster 'cluster-1' with one data center 'dataCenter-1'\r\n# The data center 'dataCenter-1' has two racks: 'seed' and 'rack-1'\r\n# The rack 'seed' has two K8S nodes: 'kube-node-1' and 'kube-node-2'\r\ncluster-1.dataCenter-1.seed=kube-node-1 # K8s node 'kube-node-1' is assigned to\r\n                                        # the rack 'seed' in the data center\r\n                                        # 'dataCenter-1' in the cluster\r\n             "]
[64.658773, "o", "                           # 'cluster-1'\r\ncluster-1.dataCenter-1.seed=kube-node-2\r\n\r\n\u001b[7mproperties/cluster-1.dataCenter-1.init.properties\u001b[27m\u001b[K"]
[68.031919, "o", "\r\u001b[K# The rack 'rack-1' has one K8S node: 'kube-node-3'\r\ncluster-1.dataCenter-1.rack-1=kube-node-3\r\n\r\n\u001b[7m(END)\u001b[27m\u001b[K"]
[73.397761, "o", "\r\u001b[K \u001b[K:\b:"]
[73.469629, "o", "\u001b[Kq\bq\r\u001b[K\u001b[?1l\u001b>\u001b[?1049l"]
[73.47054, "o", "\u001b]0;~/src/k8s/cassandra\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~/src/k8s/cassandra\u001b[0m\r\r\n$ "]
[75.446219, "o", "."]
[75.501084, "o", "/"]
[75.803104, "o", "o"]
[75.936302, "o", "perator "]
[76.931094, "o", "c"]
[77.045453, "o", " "]
[77.270473, "o", "c"]
[77.431691, "o", "l"]
[77.527902, "o", " "]
[78.218837, "o", "p"]
[78.359913, "o", "r"]
[78.494926, "o", "o"]
[78.611635, "o", "perties/"]
[79.685561, "o", "c"]
[79.879315, "o", "l"]
[80.004583, "o", "\u0007uster-1.dataCenter-"]
[80.673056, "o", "1"]
[81.409919, "o", "."]
[81.669711, "o", "i"]
[81.790426, "o", "nit.properties "]
[82.743048, "o", "\r\n"]
[84.147236, "o", "DEBUG: createNamespace: kubectl:\r\nnamespace/cassandra created\r\n"]
[84.280904, "o", "DEBUG: createCluster: Removing modified Cassandra nodes...\r\n"]
[85.654082, "o", "DEBUG: createCluster: ...Modified Cassandra nodes removed\r\n"]
[86.110531, "o", "DEBUG: createNodeLabel: kubectl:\r\nnode/kube-node-3 labeled\r\n"]
[86.423812, "o", "DEBUG: createStorageClass: kubectl:\r\nstorageclass.storage.k8s.io/local-storage created\r\n"]
[88.116799, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-1-kube-node-3-0 created\r\n"]
[88.722261, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-1-kube-node-3-1 created\r\n"]
[89.174139, "o", "DEBUG: createNodeLabel: kubectl:\r\nnode/kube-node-2 labeled\r\n"]
[90.866306, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-seed-kube-node-2-0 created\r\n"]
[91.484462, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-seed-kube-node-2-1 created\r\n"]
[91.950524, "o", "DEBUG: createNodeLabel: kubectl:\r\nnode/kube-node-1 labeled\r\n"]
[93.65638, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-seed-kube-node-1-0 created\r\n"]
[94.261167, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-seed-kube-node-1-1 created\r\n"]
[95.091581, "o", "DEBUG: createClientService: kubectl:\r\nservice/client-cluster-1 created\r\n"]
[95.911996, "o", "DEBUG: createDataCenterService: kubectl:\r\nservice/cluster-1-datacenter-1 created\r\n"]
[96.411653, "o", "WARN: createStatefulSet: Not enough instances in rack \"cluster-1.dataCenter-1.seed\": desired replicas: \"10\", available instances: \"4\"\r\nWARN: createStatefulSet: Scale down desired replicas to available instances\r\n"]
[96.735044, "o", "DEBUG: createStatefulSet: kubectl:\r\nstatefulset.apps/cluster-1-datacenter-1-seed created\r\n"]
[97.001261, "o", "DEBUG: waitUntilRunning: Waiting for Pods...\r\n"]
[97.392536, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[97.739535, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[98.083602, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[98.432501, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[98.79907, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[99.147029, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[99.507464, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[99.847308, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[100.189559, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[100.5973, "o", "DEBUG: waitUntilRunning: 1/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[101.00384, "o", "DEBUG: waitUntilRunning: 1/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[101.404865, "o", "DEBUG: waitUntilRunning: 1/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[101.813599, "o", "DEBUG: waitUntilRunning: 1/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[102.22073, "o", "DEBUG: waitUntilRunning: 1/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[102.69292, "o", "DEBUG: waitUntilRunning: 2/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[103.095808, "o", "DEBUG: waitUntilRunning: 2/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[103.507699, "o", "DEBUG: waitUntilRunning: 2/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[103.985236, "o", "DEBUG: waitUntilRunning: 2/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[104.489857, "o", "DEBUG: waitUntilRunning: 3/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[104.931149, "o", "DEBUG: waitUntilRunning: 3/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[105.382522, "o", "DEBUG: waitUntilRunning: 3/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[105.824616, "o", "DEBUG: waitUntilRunning: 3/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[106.262382, "o", "DEBUG: waitUntilRunning: 3/4 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[106.713959, "o", "DEBUG: waitUntilRunning: All pods (4) in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[107.322309, "o", "WARN: createStatefulSet: Not enough instances in rack \"cluster-1.dataCenter-1.rack-1\": desired replicas: \"10\", available instances: \"2\"\r\nWARN: createStatefulSet: Scale down desired replicas to available instances\r\n"]
[107.725281, "o", "DEBUG: createStatefulSet: kubectl:\r\nstatefulset.apps/cluster-1-datacenter-1-rack-1 created\r\n"]
[108.063816, "o", "DEBUG: waitUntilRunning: Waiting for Pods...\r\n"]
[108.479223, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[108.929504, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[109.377474, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[109.805552, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[110.247754, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[110.781732, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[111.292743, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[111.77667, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[112.241192, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[112.791329, "o", "DEBUG: waitUntilRunning: All pods (2) in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[112.792932, "o", "DEBUG: createCluster: Wait until all new/modified/restarted Cassandra nodes are running...\r\n"]
[113.004381, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-3\"...\r\n"]
[287.458724, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-1-0\" on node \"kube-node-3\" is running\r\n"]
[295.970994, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-1-1\" on node \"kube-node-3\" is running\r\n"]
[296.106136, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-2\"...\r\n"]
[304.562514, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-seed-1\" on node \"kube-node-2\" is running\r\n"]
[313.080382, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-seed-3\" on node \"kube-node-2\" is running\r\n"]
[313.204549, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-1\"...\r\n"]
[321.446766, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-seed-0\" on node \"kube-node-1\" is running\r\n"]
[330.068278, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-seed-2\" on node \"kube-node-1\" is running\r\nDEBUG: createCluster: ...All new/modified/restarted Cassandra nodes are running\r\nDEBUG: createCluster: Cleaning all previously existing nodes...\r\nDEBUG: createCluster: ...All previously existing nodes were cleanup\r\n"]
[330.068427, "o", "\u001b]0;~/src/k8s/cassandra\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~/src/k8s/cassandra\u001b[0m\r\r\n$ "]
[358.184157, "o", "kubectl exec clus"]
[358.184811, "o", "ter-1"]
[358.185594, "o", "-datace"]
[358.187801, "o", "nter-1-rack-1-0 -n cassandra -- nodetool status"]
[361.450708, "o", "\r\n"]
[368.639426, "o", "Datacenter: dataCenter-1\r\n========================\r\nStatus=Up/Down\r\n|/ State=Normal/Leaving/Joining/Moving\r\n"]
[368.640314, "o", "--  Address     Load       Tokens       Owns (effective)  "]
[368.640955, "o", "Host ID                               "]
[368.641644, "o", "Rack\r\n"]
[368.644788, "o", "UN  10.244.2.4  77.59 KiB  "]
[368.645639, "o", "32           37.3%             d0de81c1-f761-4cf3-ac4d-90f886e5ae05  rack-1\r\n"]
[368.64692, "o", "UN  10.244.6.4  "]
[368.647243, "o", "70.81 KiB  32           32.3%             2ec07139-24ab-4fa8-8544-507cc32cf3e5  seed\r\n"]
[368.649858, "o", "UN  10.244.6.5  77.63 KiB  32           41.1%             05379dd5-57b0-4f6a-b15a-0d0265ad9a40  seed\r\n"]
[368.650715, "o", "UN  10.244.5.5  65.87 KiB  32           30.9%             "]
[368.651431, "o", "057b08f8-c650-45e9-9d54-42780059b9d7  seed\r\n"]
[368.652974, "o", "UN  10.244.5.6  75.9 KiB   32           "]
[368.653284, "o", "34.1%           "]
[368.654083, "o", "  cf49c7c8-6527-4188-b4b6-619e9f9a69e6  seed\r\n"]
[368.65605, "o", "UN  10.244.2.3  65.87 KiB  32           "]
[368.657063, "o", "24.3%             ea82d549-189d-43a4-8f56-f9ace7b98903  rack-1\r\n\r\n"]
[368.686378, "o", "\u001b]0;~/src/k8s/cassandra\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~/src/k8s/cassandra\u001b[0m\r\r\n$ "]
[372.926883, "o", "m"]
[373.146684, "o", "o"]
[373.289323, "o", "r"]
[373.384381, "o", "e"]
[373.423181, "o", " "]
[374.398227, "o", "p"]
[374.586759, "o", "r"]
[374.850336, "o", "o"]
[375.021158, "o", "perties/"]
[377.469324, "o", "c"]
[377.584886, "o", "l"]
[377.714869, "o", "\u0007uster-1.dataCenter-"]
[380.760107, "o", "1"]
[381.22699, "o", "."]
[381.665701, "o", "m"]
[381.802161, "o", "ove.add.nodes.properties "]
[384.296954, "o", "\r\n"]
[384.3172, "o", "\u001b[?1049h\u001b[?1h\u001b=\rnamespace=cassandra\r\n\r\noverwrite=true # We set 'overwrite' to 'true' because we move\r\n               # the K8S node 'kube-node-2' from rack 'seed' to rack 'rack-2'\r\n               # in data center 'dataCenter-1' in cluster 'cluster-1'\r\n\r\npersistentVolume.storageType.cluster-1=local\r\npersistentVolume.dataDirectory.cluster-1=/data/cassandra\r\npersistentVolume.capacity.cluster-1=2Gi\r\nstatefulSet.resource.limit.cpu.cluster-1=500m\r\nstatefulSet.resource.limit.memory.cluster-1=1Gi\r\nstatefulSet.resource.request.cpu.cluster-1=500m\r\nstatefulSet.resource.request.memory.cluster-1=1Gi\r\nstatefulSet.env.maxHeapSize.cluster-1=512M\r\nstatefulSet.env.heapNewSize.cluster-1=100M\r\nstatefulSet.storageCapacity.cluster-1=1Gi\r\nstatefulSet.replicas.cluster-1=10\r\ninstances.cluster-1=2\r\n\r\n# We add the K8S node 'kube-node-4' to rack 'rack-1' in data center 'dataCenter- \b1'\r\n# in cluster 'cluster-1'\r\ncluster-1.dataCenter-1.rack-1=kube-node-4\r\n\u001b[7mproperties/cluster-1.dataCenter-1.move.add.nodes.properties\u001b[27m\u001b[K"]
[393.273854, "o", "\r\u001b[K\r\n# We add rack 'rack-2' in data center 'dataCenter-1' in cluster 'cluster-1'\r\n# We assign node 'kube-node-5' in rack 'rack-2' in data center 'dataCenter-1'\r\n# in cluster 'cluster-1'\r\ncluster-1.dataCenter-1.rack-2=kube-node-5\r\n\r\n# We move the K8S node 'kube-node-2' from rack 'seed' to rack 'rack-3'\r\n# in data center 'dataCenter-1' in cluster 'cluster-1'\r\ncluster-1.dataCenter-1.rack-3=kube-node-2\r\n\u001b[7m(END)\u001b[27m\u001b[K"]
[400.047953, "o", "\r\u001b[K \u001b[K:\b:"]
[400.111969, "o", "\u001b[Kq\bq\r\u001b[K\u001b[?1l\u001b>\u001b[?1049l"]
[400.112901, "o", "\u001b]0;~/src/k8s/cassandra\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~/src/k8s/cassandra\u001b[0m\r\r\n$ "]
[402.208741, "o", "."]
[402.256401, "o", "/"]
[402.655488, "o", "o"]
[402.703896, "o", "p"]
[402.834108, "o", "erator "]
[403.495966, "o", "c"]
[403.599257, "o", " "]
[404.101247, "o", "c"]
[404.240295, "o", "l"]
[404.336294, "o", " "]
[405.024546, "o", "p"]
[405.202049, "o", "r"]
[405.29694, "o", "o"]
[405.449438, "o", "perties/"]
[406.361924, "o", "c"]
[406.551919, "o", "l"]
[406.687306, "o", "\u0007uster-1.dataCenter-"]
[407.921257, "o", "1"]
[409.191628, "o", "."]
[409.655807, "o", "m"]
[409.783435, "o", "ove.add.nodes.properties "]
[411.546744, "o", "\r\n"]
[412.352459, "o", "DEBUG: createCluster: Removing modified Cassandra nodes...\r\n"]
[413.308589, "o", "DEBUG: createCluster: Node \"kube-node-2\" currently in rack \"cluster-1.dataCenter-1.seed\" was modified\r\n"]
[414.573962, "o", "DEBUG: deleteNode: Decommissioning all pods in rack \"cluster-1.dataCenter-1.seed\"...\r\n"]
[414.851415, "o", "DEBUG: deleteStatefulSet: Deleting statefulSet \"cluster-1-datacenter-1-seed\"...\r\n"]
[493.021628, "o", "DEBUG: deleteStatefulSet: kubectl:\r\nstatefulset.apps \"cluster-1-datacenter-1-seed\" deleted\r\n"]
[493.613174, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-seed-0\" deleted\r\n"]
[493.880968, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-seed-kube-node-1-1\" deleted\r\n"]
[494.110401, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-seed-kube-node-1-1 created\r\n"]
[494.34905, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-seed-1\" deleted\r\n"]
[494.591981, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-seed-kube-node-2-0\" deleted\r\n"]
[494.828611, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-seed-kube-node-2-0 created\r\n"]
[495.078142, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-seed-2\" deleted\r\n"]
[495.330483, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-seed-kube-node-1-0\" deleted\r\n"]
[495.569566, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-seed-kube-node-1-0 created\r\n"]
[495.830297, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-seed-3\" deleted\r\n"]
[496.10209, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-seed-kube-node-2-1\" deleted\r\n"]
[496.327742, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-seed-kube-node-2-1 created\r\n"]
[496.328647, "o", "DEBUG: deleteNode: ...All pods in rack \"cluster-1.dataCenter-1.seed\" were decommissioned\r\n"]
[497.022133, "o", "DEBUG: releaseNodePersistentVolume: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-seed-kube-node-2-0\" deleted\r\n"]
[497.258168, "o", "DEBUG: releaseNodePersistentVolume: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-seed-kube-node-2-1\" deleted\r\n"]
[498.098889, "o", "DEBUG: deleteNodeLabel: kubectl:\r\nnode/kube-node-2 labeled\r\n"]
[498.331385, "o", "WARN: deleteNode: Not enough instances in rack \"cluster-1.dataCenter-1.seed\": desired replicas: \"4\", available instances: \"2\"\r\nWARN: deleteNode: Scale down desired replicas to available instances (2)\r\nDEBUG: deleteNode: Creating statefulSet \"cluster-1-datacenter-1-seed\"\r\n"]
[499.154843, "o", "DEBUG: createStatefulSet: kubectl:\r\nstatefulset.apps/cluster-1-datacenter-1-seed created\r\n"]
[499.408635, "o", "DEBUG: waitUntilRunning: Waiting for Pods...\r\n"]
[499.780802, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[500.145255, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[500.501349, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[500.908739, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[501.273503, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[501.681176, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[502.12226, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[502.499824, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[502.920891, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[503.314032, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[503.779359, "o", "DEBUG: waitUntilRunning: All pods (2) in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[503.780626, "o", "DEBUG: createCluster: ...Modified Cassandra nodes removed\r\n"]
[504.302446, "o", "DEBUG: createNodeLabel: kubectl:\r\nnode/kube-node-4 labeled\r\n"]
[506.363069, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-1-kube-node-4-0 created\r\n"]
[507.017085, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-1-kube-node-4-1 created\r\n"]
[507.572144, "o", "DEBUG: createNodeLabel: kubectl:\r\nnode/kube-node-2 labeled\r\n"]
[509.632608, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-3-kube-node-2-0 created\r\n"]
[510.288414, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-3-kube-node-2-1 created\r\n"]
[510.849149, "o", "DEBUG: createNodeLabel: kubectl:\r\nnode/kube-node-5 labeled\r\n"]
[512.883987, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-2-kube-node-5-0 created\r\n"]
[513.576565, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-2-kube-node-5-1 created\r\n"]
[515.019275, "o", "WARN: createStatefulSet: Not enough instances in rack \"cluster-1.dataCenter-1.rack-3\": desired replicas: \"10\", available instances: \"2\"\r\nWARN: createStatefulSet: Scale down desired replicas to available instances\r\n"]
[515.370247, "o", "DEBUG: createStatefulSet: kubectl:\r\nstatefulset.apps/cluster-1-datacenter-1-rack-3 created\r\n"]
[515.657939, "o", "DEBUG: waitUntilRunning: Waiting for Pods...\r\n"]
[516.091767, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[516.474186, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[516.911391, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[517.314369, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[517.818465, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[518.262701, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[518.667069, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[519.094216, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[519.521119, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[519.982168, "o", "DEBUG: waitUntilRunning: All pods (2) in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[520.617527, "o", "WARN: createStatefulSet: Not enough instances in rack \"cluster-1.dataCenter-1.rack-2\": desired replicas: \"10\", available instances: \"2\"\r\nWARN: createStatefulSet: Scale down desired replicas to available instances\r\n"]
[521.018267, "o", "DEBUG: createStatefulSet: kubectl:\r\nstatefulset.apps/cluster-1-datacenter-1-rack-2 created\r\n"]
[521.307249, "o", "DEBUG: waitUntilRunning: Waiting for Pods...\r\n"]
[521.779974, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[522.224004, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[522.680697, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[523.212683, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[523.689545, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[524.132563, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[524.594058, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[525.113921, "o", "DEBUG: waitUntilRunning: All pods (2) in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[525.8146, "o", "WARN: createStatefulSet: Not enough instances in rack \"cluster-1.dataCenter-1.rack-1\": desired replicas: \"10\", available instances: \"4\"\r\nWARN: createStatefulSet: Scale down desired replicas to available instances\r\n"]
[526.325296, "o", "DEBUG: deleteStatefulSet: Deleting statefulSet \"cluster-1-datacenter-1-rack-1\"...\r\n"]
[565.828803, "o", "DEBUG: deleteStatefulSet: kubectl:\r\nstatefulset.apps \"cluster-1-datacenter-1-rack-1\" deleted\r\n"]
[566.510665, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-rack-1-0\" deleted\r\n"]
[566.841748, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-rack-1-kube-node-3-0\" deleted\r\n"]
[567.15039, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-1-kube-node-3-0 created\r\n"]
[567.453982, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-rack-1-1\" deleted\r\n"]
[567.775458, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-rack-1-kube-node-3-1\" deleted\r\n"]
[568.060205, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-1-kube-node-3-1 created\r\n"]
[568.351184, "o", "DEBUG: createStatefulSet: kubectl:\r\nstatefulset.apps/cluster-1-datacenter-1-rack-1 created\r\n"]
[568.650936, "o", "DEBUG: waitUntilRunning: Waiting for Pods...\r\n"]
[569.093994, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[569.526202, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[570.008464, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[570.521219, "o", "DEBUG: waitUntilRunning: 1/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[571.079751, "o", "DEBUG: waitUntilRunning: 1/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[571.522227, "o", "DEBUG: waitUntilRunning: 1/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[572.005927, "o", "DEBUG: waitUntilRunning: 1/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[572.480479, "o", "DEBUG: waitUntilRunning: 1/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[573.014436, "o", "DEBUG: waitUntilRunning: 2/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[573.574672, "o", "DEBUG: waitUntilRunning: 2/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[574.021428, "o", "DEBUG: waitUntilRunning: 2/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[574.51746, "o", "DEBUG: waitUntilRunning: 2/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[575.191323, "o", "DEBUG: waitUntilRunning: 3/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[575.72659, "o", "DEBUG: waitUntilRunning: 3/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[576.282068, "o", "DEBUG: waitUntilRunning: 3/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[576.815842, "o", "DEBUG: waitUntilRunning: 3/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[577.456375, "o", "DEBUG: waitUntilRunning: All pods (4) in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[577.45728, "o", "DEBUG: createCluster: Wait until all new/modified/restarted Cassandra nodes are running...\r\n"]
[577.712012, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-1\"...\r\n"]
[587.375564, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-seed-0\" on node \"kube-node-1\" is running\r\n"]
[597.469938, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-seed-1\" on node \"kube-node-1\" is running\r\n"]
[597.679711, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-4\"...\r\n"]
[785.239944, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-1-0\" on node \"kube-node-4\" is running\r\n"]
[794.654083, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-1-2\" on node \"kube-node-4\" is running\r\n"]
[794.878124, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-3\"...\r\n"]
[803.76945, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-1-1\" on node \"kube-node-3\" is running\r\n"]
[813.544503, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-1-3\" on node \"kube-node-3\" is running\r\n"]
[813.680485, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-5\"...\r\n"]
[822.851393, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-2-0\" on node \"kube-node-5\" is running\r\n"]
[831.869706, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-2-1\" on node \"kube-node-5\" is running\r\n"]
[832.009068, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-2\"...\r\n"]
[840.951413, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-3-0\" on node \"kube-node-2\" is running\r\n"]
[850.7831, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-3-1\" on node \"kube-node-2\" is running\r\nDEBUG: createCluster: ...All new/modified/restarted Cassandra nodes are running\r\nDEBUG: createCluster: Cleaning all previously existing nodes...\r\n"]
[851.16386, "o", "DEBUG: nodetool: Running nodetool on pod \"cluster-1-datacenter-1-rack-1-1\" on node \"kube-node-3\" with arguments \"cleanup\"...\r\n"]
[859.640544, "o", "DEBUG: nodetool: ...nodetool on pod \"cluster-1-datacenter-1-rack-1-1\" on node \"kube-node-3\" finished\r\nDEBUG: nodetool: Running nodetool on pod \"cluster-1-datacenter-1-rack-1-3\" on node \"kube-node-3\" with arguments \"cleanup\"...\r\n"]
[868.057435, "o", "DEBUG: nodetool: ...nodetool on pod \"cluster-1-datacenter-1-rack-1-3\" on node \"kube-node-3\" finished\r\n"]
[868.423685, "o", "DEBUG: nodetool: Running nodetool on pod \"cluster-1-datacenter-1-seed-0\" on node \"kube-node-1\" with arguments \"cleanup\"...\r\n"]
[876.558197, "o", "DEBUG: nodetool: ...nodetool on pod \"cluster-1-datacenter-1-seed-0\" on node \"kube-node-1\" finished\r\nDEBUG: nodetool: Running nodetool on pod \"cluster-1-datacenter-1-seed-1\" on node \"kube-node-1\" with arguments \"cleanup\"...\r\n"]
[885.445465, "o", "DEBUG: nodetool: ...nodetool on pod \"cluster-1-datacenter-1-seed-1\" on node \"kube-node-1\" finished\r\nDEBUG: createCluster: ...All previously existing nodes were cleanup\r\n"]
[885.447025, "o", "\u001b]0;~/src/k8s/cassandra\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~/src/k8s/cassandra\u001b[0m\r\r\n$ "]
[901.921388, "o", "kubectl exec cluster"]
[901.924958, "o", "-1-datacenter-1-rack-1-0 -n cassandra -- nodetool status"]
[902.932528, "o", "\r\n"]
[910.465756, "o", "Datacenter: dataCenter-1\r\n====="]
[910.466399, "o", "======"]
[910.466938, "o", "=="]
[910.468098, "o", "===========\r\nStatus=Up/Down\r\n|/ State=Normal/Leaving/Joining/Moving\r\n"]
[910.469197, "o", "--  Address     Load       Tokens       Owns (effective)"]
[910.469742, "o", "  Host ID                               Rack\r\n"]
[910.474306, "o", "UN  10.244.3.4  105.33 KiB  32           21.6%             d8e3adc0-dc42-4c59-ac47-0a4eacf25ddc  rack-1\r\n"]
[910.476255, "o", "UN  "]
[910.476783, "o", "10.244.8.4  102.41 KiB  32           19.8%             469b57b3-3f59-4424-ae7a-e55b02468a04  rack-2\r\n"]
[910.478007, "o", "UN  10.244.8.5  83.2 KiB   32           "]
[910.478597, "o", "27.2%             cbb9ea8d-d719-4621-8c17-e49cefa71cd3  rack-2\r\n"]
[910.534366, "o", "UN  10.244.2.5  65.86 KiB  32           17.2%             2f6b4a1f-86b1-49b5-8f92-fa582523416b  rack-1\r\n"]
[910.536498, "o", "UN  10.244.6.6  65.86 KiB  32           16.6%             b9743f73-1771-453c-93f4-c37bdb24974b  seed\r\n"]
[910.538353, "o", "UN  10.244.2.6  96.63 KiB  32           18.4%             d968e3bb-3c01-4427-9cba-01d7214e075f  rack-1\r\n"]
[910.5401, "o", "UN  10.244.6.7  65.87 KiB  32           16.7%             600e7f76-8d26-4e3d-8284-2ef6e09d672a  seed\r\n"]
[910.541522, "o", "UN  10.244.5.7  65.86 KiB  32           21.3%             a8dbc7db-8cbc-45dc-840c-88074d69d134  rack-3\r\n"]
[910.543166, "o", "UN  10.244.3.3  65.85 KiB  32           22.4%             bca9a89a-bf1a-46db-86cd-231ea481b860  rack-1\r\n"]
[910.546771, "o", "UN  10.244.5.8  65.91 KiB  32           18.7%             aa72ddc5-65e5-416e-9e20-0f8035f9ce18  rack-3\r\n\r\n"]
[910.57108, "o", "\u001b]0;~/src/k8s/cassandra\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~/src/k8s/cassandra\u001b[0m\r\r\n$ "]
[921.421781, "o", "kubectl exec cluster-1-datacenter-1-rack-1-0 -n cassandra -- nodetool status"]
[923.595336, "o", "|"]
[923.931455, "o", "m \r"]
[924.157055, "o", "o"]
[924.276432, "o", "r"]
[924.380509, "o", "e"]
[924.996917, "o", "\r\n"]
[925.001217, "o", "\u001b[?1049h\u001b[?1h\u001b=\r"]
[932.956473, "o", "Datacenter: dataCenter-1\r\n========================\r\nStatus=Up/Down\r\n|/ State=Normal/Leaving/Joining/Moving\r\n"]
[932.95729, "o", "--  Address     Load       Tokens       Owns (effective)  Host ID                \b                Rack\r\n"]
[933.037793, "o", "UN  10.244.3.4  105.33 KiB  32           21.6%             d8e3adc0-dc42-4c59-ac \b47-0a4eacf25ddc  rack-1\r\n"]
[933.039905, "o", "UN  10.244.8.4  102.41 KiB  32           19.8%             469b57b3-3f59-4424-ae \b7a-e55b02468a04  rack-2\r\n"]
[933.042383, "o", "UN  10.244.8.5  83.2 KiB   32           27.2%             cbb9ea8d-d719-4621-8c1 \b7-e49cefa71cd3  rack-2\r\n"]
[933.044239, "o", "UN  10.244.2.5  65.86 KiB  32           17.2%             2f6b4a1f-86b1-49b5-8f9 \b2-fa582523416b  rack-1\r\n"]
[933.046082, "o", "UN  10.244.6.6  65.86 KiB  32           16.6%             b9743f73-1771-453c-93f \b4-c37bdb24974b  seed\r\n"]
[933.047578, "o", "UN  10.244.2.6  96.63 KiB  32           18.4%             d968e3bb-3c01-4427-9cb \ba-01d7214e075f  rack-1\r\n"]
[933.048914, "o", "UN  10.244.6.7  65.87 KiB  32           16.7%             600e7f76-8d26-4e3d-828 \b4-2ef6e09d672a  seed\r\n"]
[933.050445, "o", "UN  10.244.5.7  65.86 KiB  32           21.3%             a8dbc7db-8cbc-45dc-840 \bc-88074d69d134  rack-3\r\n"]
[933.051985, "o", "UN  10.244.3.3  65.85 KiB  32           22.4%             bca9a89a-bf1a-46db-86c \b:\u001b[K"]
[936.778053, "o", "\r\u001b[Kd-231ea481b860  rack-1\r\nUN  10.244.5.8  65.91 KiB  32           18.7%             aa72ddc5-65e5-416e-9e2 \b0-0f8035f9ce18  rack-3\r\n\r\n\u001b[7m(END)\u001b[27m\u001b[K"]
[941.967288, "o", "\r\u001b[K \u001b[K:\b:"]
[942.019339, "o", "\u001b[Kq\bq\r\u001b[K\u001b[?1l\u001b>\u001b[?1049l"]
[942.019945, "o", "\u001b]0;~/src/k8s/cassandra\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~/src/k8s/cassandra\u001b[0m\r\r\n$ "]
[950.422013, "o", "m"]
[950.612494, "o", "o"]
[950.765525, "o", "r"]
[950.870372, "o", "e"]
[950.932456, "o", " "]
[951.51628, "o", "p"]
[951.696618, "o", "r"]
[951.828247, "o", "o"]
[951.95088, "o", "perties/"]
[953.0843, "o", "c"]
[953.291764, "o", "l"]
[953.424491, "o", "\u0007uster-1.dataCenter-"]
[959.059896, "o", "2"]
[959.351647, "o", ".add.dataCenter.properties "]
[961.772996, "o", "\r\n"]
[961.796481, "o", "\u001b[?1049h\u001b[?1h\u001b=\rnamespace=cassandra\r\npersistentVolume.storageType.cluster-1=local\r\npersistentVolume.dataDirectory.cluster-1=/data/cassandra\r\npersistentVolume.capacity.cluster-1=2Gi\r\nstatefulSet.resource.limit.cpu.cluster-1=500m\r\nstatefulSet.resource.limit.memory.cluster-1=1Gi\r\nstatefulSet.resource.request.cpu.cluster-1=500m\r\nstatefulSet.resource.request.memory.cluster-1=1Gi\r\nstatefulSet.env.maxHeapSize.cluster-1=512M\r\nstatefulSet.env.heapNewSize.cluster-1=100M\r\nstatefulSet.storageCapacity.cluster-1=1Gi\r\nstatefulSet.replicas.cluster-1=10\r\ninstances.cluster-1=2\r\ninstances.cluster-1.dataCenter-2=1\r\n\r\n# We add a data center 'dataCenter-2' in cluster 'cluster-1'\r\n# We add rack 'seed' in data center 'dataCenter-2' in cluster 'cluster-1'\r\n# We assign node 'kube-node-6' in rack 'seed' in data center 'dataCenter-2'\r\n# in cluster 'cluster-1'\r\ncluster-1.dataCenter-2.seed=kube-node-6\r\n\r\n# We add rack 'rack-1' in data center 'dataCenter-2' in cluster 'cluster-1'\r\n# We assign nodes 'kube-node-7' and 'kube-node-8' in rack '"]
[961.797078, "o", "rack-1'\r\n\u001b[7mproperties/cluster-1.dataCenter-2.add.dataCenter.properties\u001b[27m\u001b[K"]
[963.877304, "o", "\r\u001b[K# in data center 'dataCenter-2' in cluster 'cluster-1'\r\ncluster-1.dataCenter-2.rack-1=kube-node-7 kube-node-8\r\n\u001b[7m(END)\u001b[27m\u001b[K"]
[965.51752, "o", "\r\u001b[K \u001b[K:\b:"]
[965.588353, "o", "\u001b[Kq\bq\r\u001b[K\u001b[?1l\u001b>\u001b[?1049l"]
[965.589261, "o", "\u001b]0;~/src/k8s/cassandra\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~/src/k8s/cassandra\u001b[0m\r\r\n$ "]
[966.569416, "o", "."]
[966.630188, "o", "/"]
[966.937199, "o", "o"]
[967.005228, "o", "p"]
[967.133477, "o", "erator "]
[967.647329, "o", "c"]
[967.749316, "o", " "]
[967.966285, "o", "c"]
[968.116315, "o", "l"]
[968.235929, "o", " "]
[968.704128, "o", "p"]
[968.86395, "o", "r"]
[968.980783, "o", "o"]
[969.09859, "o", "perties/"]
[969.862372, "o", "c"]
[969.972222, "o", "l"]
[970.090386, "o", "\u0007uster-1.dataCenter-"]
[971.308331, "o", "2"]
[971.964911, "o", ".add.dataCenter.properties "]
[973.265524, "o", "\r\n"]
[974.814202, "o", "DEBUG: createCluster: Removing modified Cassandra nodes...\r\n"]
[976.236114, "o", "DEBUG: createCluster: ...Modified Cassandra nodes removed\r\n"]
[976.2371, "o", "DEBUG: createCluster: Cluster \"cluster-1\" has a new data center \"dataCenter-2\"\r\n"]
[976.708303, "o", "DEBUG: createNodeLabel: kubectl:\r\nnode/kube-node-6 labeled\r\n"]
[978.419051, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-2-seed-kube-node-6-0 created\r\n"]
[978.931582, "o", "DEBUG: createNodeLabel: kubectl:\r\nnode/kube-node-7 labeled\r\n"]
[980.79438, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-2-rack-1-kube-node-7-0 created\r\n"]
[981.30241, "o", "DEBUG: createNodeLabel: kubectl:\r\nnode/kube-node-8 labeled\r\n"]
[982.973135, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-2-rack-1-kube-node-8-0 created\r\n"]
[982.976667, "o", "DEBUG: createCluster: New data centers were added, so we restart unmodified current racks...\r\n"]
[983.446199, "o", "DEBUG: restartStatefulSet: Deleting statefulSet \"cluster-1-datacenter-1-rack-2\"\r\n"]
[983.74584, "o", "DEBUG: deleteStatefulSet: Deleting statefulSet \"cluster-1-datacenter-1-rack-2\"...\r\n"]
[1060.688676, "o", "DEBUG: deleteStatefulSet: kubectl:\r\nstatefulset.apps \"cluster-1-datacenter-1-rack-2\" deleted\r\n"]
[1061.291414, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-rack-2-0\" deleted\r\n"]
[1061.571325, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-rack-2-kube-node-5-0\" deleted\r\n"]
[1061.796358, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-2-kube-node-5-0 created\r\n"]
[1062.054905, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-rack-2-1\" deleted\r\n"]
[1062.324006, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-rack-2-kube-node-5-1\" deleted\r\n"]
[1062.550214, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-2-kube-node-5-1 created\r\n"]
[1062.550921, "o", "DEBUG: restartStatefulSet: Creating statefulSet \"cluster-1-datacenter-1-rack-2\"\r\n"]
[1063.536082, "o", "DEBUG: createStatefulSet: kubectl:\r\nstatefulset.apps/cluster-1-datacenter-1-rack-2 created\r\n"]
[1063.799863, "o", "DEBUG: waitUntilRunning: Waiting for Pods...\r\n"]
[1064.19589, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[1064.579385, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[1064.965653, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[1065.33775, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[1065.798857, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[1066.20114, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[1066.602294, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[1066.994468, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[1067.429747, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[1067.860279, "o", "DEBUG: waitUntilRunning: All pods (2) in rack \"cluster-1.dataCenter-1.rack-2\" are in running state.\r\n"]
[1068.387547, "o", "DEBUG: restartStatefulSet: Deleting statefulSet \"cluster-1-datacenter-1-rack-1\"\r\n"]
[1068.726478, "o", "DEBUG: deleteStatefulSet: Deleting statefulSet \"cluster-1-datacenter-1-rack-1\"...\r\n"]
[1196.742419, "o", "DEBUG: deleteStatefulSet: kubectl:\r\nstatefulset.apps \"cluster-1-datacenter-1-rack-1\" deleted\r\n"]
[1197.328877, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-rack-1-0\" deleted\r\n"]
[1197.609951, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-rack-1-kube-node-4-1\" deleted\r\n"]
[1197.850813, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-1-kube-node-4-1 created\r\n"]
[1198.083702, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-rack-1-1\" deleted\r\n"]
[1198.354132, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-rack-1-kube-node-3-1\" deleted\r\n"]
[1198.593156, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-1-kube-node-3-1 created"]
[1198.593903, "o", "\r\n"]
[1198.851247, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-rack-1-2\" deleted\r\n"]
[1199.132257, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-rack-1-kube-node-4-0\" deleted\r\n"]
[1199.361128, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-1-kube-node-4-0 created\r\n"]
[1199.595691, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-rack-1-3\" deleted\r\n"]
[1199.862333, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-rack-1-kube-node-3-0\" deleted\r\n"]
[1200.085592, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-1-kube-node-3-0 created\r\n"]
[1200.086821, "o", "DEBUG: restartStatefulSet: Creating statefulSet \"cluster-1-datacenter-1-rack-1\""]
[1200.087713, "o", "\r\n"]
[1201.070898, "o", "DEBUG: createStatefulSet: kubectl:\r\nstatefulset.apps/cluster-1-datacenter-1-rack-1 created\r\n"]
[1201.327941, "o", "DEBUG: waitUntilRunning: Waiting for Pods...\r\n"]
[1201.700179, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1202.081894, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1202.440955, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1202.834074, "o", "DEBUG: waitUntilRunning: 0/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1203.285202, "o", "DEBUG: waitUntilRunning: 1/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1203.702207, "o", "DEBUG: waitUntilRunning: 1/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1204.089451, "o", "DEBUG: waitUntilRunning: 1/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1204.485374, "o", "DEBUG: waitUntilRunning: 1/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1204.991707, "o", "DEBUG: waitUntilRunning: 2/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1205.478542, "o", "DEBUG: waitUntilRunning: 2/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1205.89612, "o", "DEBUG: waitUntilRunning: 2/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1206.310117, "o", "DEBUG: waitUntilRunning: 2/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1206.717176, "o", "DEBUG: waitUntilRunning: 2/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1207.25312, "o", "DEBUG: waitUntilRunning: 3/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1207.702074, "o", "DEBUG: waitUntilRunning: 3/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1208.139986, "o", "DEBUG: waitUntilRunning: 3/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1208.572915, "o", "DEBUG: waitUntilRunning: 3/4 pods in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1210.027401, "o", "DEBUG: waitUntilRunning: All pods (4) in rack \"cluster-1.dataCenter-1.rack-1\" are in running state.\r\n"]
[1210.589325, "o", "DEBUG: restartStatefulSet: Deleting statefulSet \"cluster-1-datacenter-1-rack-3\"\r\n"]
[1210.96132, "o", "DEBUG: deleteStatefulSet: Deleting statefulSet \"cluster-1-datacenter-1-rack-3\"...\r\n"]
[1228.994307, "o", "DEBUG: deleteStatefulSet: kubectl:\r\nstatefulset.apps \"cluster-1-datacenter-1-rack-3\" deleted\r\n"]
[1229.795529, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-rack-3-0\" deleted\r\n"]
[1230.195022, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-rack-3-kube-node-2-1\" deleted\r\n"]
[1230.486787, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-3-kube-node-2-1 created\r\n"]
[1230.805058, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-rack-3-1\" deleted\r\n"]
[1231.177572, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-rack-3-kube-node-2-0\" deleted\r\n"]
[1231.48295, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-rack-3-kube-node-2-0 created\r\n"]
[1231.48395, "o", "DEBUG: restartStatefulSet: Creating statefulSet \"cluster-1-datacenter-1-rack-3\"\r\n"]
[1232.729062, "o", "DEBUG: createStatefulSet: kubectl:\r\nstatefulset.apps/cluster-1-datacenter-1-rack-3 created\r\n"]
[1233.112235, "o", "DEBUG: waitUntilRunning: Waiting for Pods...\r\n"]
[1233.587045, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[1234.090882, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[1234.596057, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[1235.318295, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[1235.862076, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[1236.400318, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[1237.884009, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[1238.500541, "o", "DEBUG: waitUntilRunning: All pods (2) in rack \"cluster-1.dataCenter-1.rack-3\" are in running state.\r\n"]
[1239.211585, "o", "DEBUG: restartStatefulSet: Deleting statefulSet \"cluster-1-datacenter-1-seed\"\r\n"]
[1239.785917, "o", "DEBUG: deleteStatefulSet: Deleting statefulSet \"cluster-1-datacenter-1-seed\"...\r\n"]
[1253.020164, "o", "DEBUG: deleteStatefulSet: kubectl:\r\nstatefulset.apps \"cluster-1-datacenter-1-seed\" deleted\r\n"]
[1253.702549, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-seed-0\" deleted\r\n"]
[1254.036565, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-seed-kube-node-1-1\" deleted\r\n"]
[1254.281374, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-seed-kube-node-1-1 created\r\n"]
[1254.581521, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolumeclaim \"local-data-cluster-1-datacenter-1-seed-1\" deleted\r\n"]
[1254.863925, "o", "DEBUG: releasePersistentVolumeClaim: kubectl:\r\npersistentvolume \"cluster-1-datacenter-1-seed-kube-node-1-0\" deleted\r\n"]
[1255.126612, "o", "DEBUG: boundInstancePersistentVolume: kubectl:\r\npersistentvolume/cluster-1-datacenter-1-seed-kube-node-1-0 created\r\n"]
[1255.127428, "o", "DEBUG: restartStatefulSet: Creating statefulSet \"cluster-1-datacenter-1-seed\"\r\n"]
[1256.107684, "o", "DEBUG: createStatefulSet: kubectl:\r\nstatefulset.apps/cluster-1-datacenter-1-seed created\r\n"]
[1256.378214, "o", "DEBUG: waitUntilRunning: Waiting for Pods...\r\n"]
[1256.758631, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[1257.135409, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[1257.528462, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[1257.902961, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[1258.267219, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[1258.710871, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[1259.112214, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[1259.526083, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[1259.912554, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[1260.338407, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[1260.811238, "o", "DEBUG: waitUntilRunning: All pods (2) in rack \"cluster-1.dataCenter-1.seed\" are in running state.\r\n"]
[1260.81247, "o", "DEBUG: createCluster: ...Current racks restarted\r\n"]
[1262.441118, "o", "DEBUG: createDataCenterService: kubectl:\r\nservice/cluster-1-datacenter-2 created\r\n"]
[1263.242608, "o", "WARN: createStatefulSet: Not enough instances in rack \"cluster-1.dataCenter-2.seed\": desired replicas: \"10\", available instances: \"1\"\r\nWARN: createStatefulSet: Scale down desired replicas to available instances\r\n"]
[1263.616857, "o", "DEBUG: createStatefulSet: kubectl:\r\nstatefulset.apps/cluster-1-datacenter-2-seed created\r\n"]
[1263.942097, "o", "DEBUG: waitUntilRunning: Waiting for Pods...\r\n"]
[1264.37031, "o", "DEBUG: waitUntilRunning: 0/1 pods in rack \"cluster-1.dataCenter-2.seed\" are in running state.\r\n"]
[1264.810078, "o", "DEBUG: waitUntilRunning: 0/1 pods in rack \"cluster-1.dataCenter-2.seed\" are in running state.\r\n"]
[1265.275179, "o", "DEBUG: waitUntilRunning: 0/1 pods in rack \"cluster-1.dataCenter-2.seed\" are in running state.\r\n"]
[1265.689469, "o", "DEBUG: waitUntilRunning: 0/1 pods in rack \"cluster-1.dataCenter-2.seed\" are in running state.\r\n"]
[1266.173154, "o", "DEBUG: waitUntilRunning: All pods (1) in rack \"cluster-1.dataCenter-2.seed\" are in running state.\r\n"]
[1267.031999, "o", "WARN: createStatefulSet: Not enough instances in rack \"cluster-1.dataCenter-2.rack-1\": desired replicas: \"10\", available instances: \"2\"\r\nWARN: createStatefulSet: Scale down desired replicas to available instances\r\n"]
[1267.485617, "o", "DEBUG: createStatefulSet: kubectl:\r\nstatefulset.apps/cluster-1-datacenter-2-rack-1 created\r\n"]
[1267.912218, "o", "DEBUG: waitUntilRunning: Waiting for Pods...\r\n"]
[1268.405628, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-2.rack-1\" are in running state.\r\n"]
[1269.001078, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-2.rack-1\" are in running state.\r\n"]
[1269.703731, "o", "DEBUG: waitUntilRunning: 0/2 pods in rack \"cluster-1.dataCenter-2.rack-1\" are in running state.\r\n"]
[1270.599597, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-2.rack-1\" are in running state.\r\n"]
[1271.230303, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-2.rack-1\" are in running state.\r\n"]
[1271.908823, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-2.rack-1\" are in running state.\r\n"]
[1272.618541, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-2.rack-1\" are in running state.\r\n"]
[1273.324248, "o", "DEBUG: waitUntilRunning: 1/2 pods in rack \"cluster-1.dataCenter-2.rack-1\" are in running state.\r\n"]
[1274.127002, "o", "DEBUG: waitUntilRunning: All pods (2) in rack \"cluster-1.dataCenter-2.rack-1\" are in running state.\r\n"]
[1274.127982, "o", "DEBUG: createCluster: Wait until all new/modified/restarted Cassandra nodes are running...\r\n"]
[1274.440771, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-4\"...\r\n"]
[1596.242216, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-1-1\" on node \"kube-node-4\" is running\r\n"]
[1723.652321, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-1-3\" on node \"kube-node-4\" is running\r\n"]
[1723.88205, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-3\"...\r\n"]
[1733.862444, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-1-0\" on node \"kube-node-3\" is running\r\n"]
[1744.462344, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-1-2\" on node \"kube-node-3\" is running\r\n"]
[1744.624214, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-2\"...\r\n"]
[1755.05179, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-3-0\" on node \"kube-node-2\" is running\r\n"]
[1764.846462, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-3-1\" on node \"kube-node-2\" is running\r\n"]
[1764.994369, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-5\"...\r\n"]
[1774.649397, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-2-0\" on node \"kube-node-5\" is running\r\n"]
[2162.547884, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-rack-2-1\" on node \"kube-node-5\" is running\r\n"]
[2162.69983, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-1\"...\r\n"]
[2172.865527, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-seed-0\" on node \"kube-node-1\" is running\r\n"]
[2182.755202, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-1-seed-1\" on node \"kube-node-1\" is running\r\n"]
[2182.899892, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-7\"...\r\n"]
[2193.041555, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-2-rack-1-1\" on node \"kube-node-7\" is running\r\n"]
[2193.191398, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-8\"...\r\n"]
[2203.044835, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-2-rack-1-0\" on node \"kube-node-8\" is running\r\n"]
[2203.190001, "o", "DEBUG: createCluster: Wait for Cassandra's pods on node \"kube-node-6\"...\r\n"]
[2213.55035, "o", "DEBUG: createCluster: Cassandra pod \"cluster-1-datacenter-2-seed-0\" on node \"kube-node-6\" is running\r\nDEBUG: createCluster: ...All new/modified/restarted Cassandra nodes are running\r\n"]
[2214.166936, "o", "DEBUG: nodetool: Running nodetool on pod \"cluster-1-datacenter-2-seed-0\" on node \"kube-node-6\" with arguments \"rebuild -- dataCenter-1\"...\r\n"]
[2220.948552, "o", "ERROR: nodetool: kubectl:\r\n/usr/local/apache-cassandra-3.11.2/bin/nodetool: 74: [: rebuild: unexpected operator\r\nnodetool: Unable to find sufficient sources for streaming range (-2668837112647938701,-2655770691412809304] in keyspace system_auth with RF=1. Ensure this keyspace contains replicas in the source datacenter.\r\nSee 'nodetool help' or 'nodetool help <command>'.\r\ncommand terminated with exit code 1\r\nDEBUG: nodetool: ...nodetool on pod \"cluster-1-datacenter-2-seed-0\" on node \"kube-node-6\" finished\r\n"]
[2221.209327, "o", "DEBUG: nodetool: Running nodetool on pod \"cluster-1-datacenter-2-rack-1-1\" on node \"kube-node-7\" with arguments \"rebuild -- dataCenter-1\"...\r\n"]
[2227.845138, "o", "ERROR: nodetool: kubectl:\r\n/usr/local/apache-cassandra-3.11.2/bin/nodetool: 74: [: rebuild: unexpected operator\r\nnodetool: Unable to find sufficient sources for streaming range (-5821085813521078174,-5551580249879821220] in keyspace system_auth with RF=1. Ensure this keyspace contains replicas in the source datacenter.\r\nSee 'nodetool help' or 'nodetool help <command>'.\r\ncommand terminated with exit code 1\r\nDEBUG: nodetool: ...nodetool on pod \"cluster-1-datacenter-2-rack-1-1\" on node \"kube-node-7\" finished\r\n"]
[2228.116456, "o", "DEBUG: nodetool: Running nodetool on pod \"cluster-1-datacenter-2-rack-1-0\" on node \"kube-node-8\" with arguments \"rebuild -- dataCenter-1\"...\r\n"]
[2234.545184, "o", "ERROR: nodetool: kubectl:\r\n/usr/local/apache-cassandra-3.11.2/bin/nodetool: 74: [: rebuild: unexpected operator\r\nnodetool: Unable to find sufficient sources for streaming range (3982684567670191103,4006924852129949346] in keyspace system_auth with RF=1. Ensure this keyspace contains replicas in the source datacenter.\r\nSee 'nodetool help' or 'nodetool help <command>'.\r\ncommand terminated with exit code 1\r\nDEBUG: nodetool: ...nodetool on pod \"cluster-1-datacenter-2-rack-1-0\" on node \"kube-node-8\" finished\r\n"]
[2234.54654, "o", "ERROR: createCluster: clustertool failed on nodes \"kube-node-6\r\nkube-node-7\r\nkube-node-8\"\r\n"]
[2234.547962, "o", "\u001b]0;~/src/k8s/cassandra\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~/src/k8s/cassandra\u001b[0m\r\r\n$ "]
[2266.012963, "o", "kubectl exec cluster-1-datacenter-2-rack-1-0 -n cassandra -- nodetool status"]
[2268.014223, "o", "|"]
[2268.450111, "o", "m \r"]
[2268.655831, "o", "o"]
[2268.782041, "o", "r"]
[2268.903259, "o", "e"]
[2269.436956, "o", "\r\n"]
[2269.439454, "o", "\u001b[?1049h\u001b[?1h\u001b=\r"]
[2278.744338, "o", "Datacenter: dataCenter-1\r\n========================\r\nStatus=Up/Down\r\n|/ State=Normal/Leaving/Joining/Moving\r\n"]
[2278.745386, "o", "--  Address      Load       Tokens       Owns (effective)  Host ID               \b                 Rack\r\n"]
[2278.75139, "o", "UN  10.244.3.5   65.86 KiB  32           16.6%             fe147c5f-89ec-4d3e-a9 \bba-6212b0f8b7b4  rack-1\r\n"]
[2278.754272, "o", "UN  10.244.8.6   70.95 KiB  32           14.7%             17370602-38ce-4c37-98 \b9f-7c983d5214e9  rack-2\r\n"]
[2278.757342, "o", "UN  10.244.3.6   65.86 KiB  32           12.4%             644238e9-2f4a-43e0-86 \b92-6b82cf451340  rack-1\r\n"]
[2278.839748, "o", "UN  10.244.8.7   65.86 KiB  32           13.7%             ec09aac1-2ad4-4943-88 \b0c-75efaf4cb298  rack-2\r\n"]
[2278.840945, "o", "UN  10.244.2.7   65.85 KiB  32           17.4%             8a34d5c8-c4cc-4ee2-80 \bf5-cca8c31636a2  rack-1\r\n"]
[2278.84341, "o", "UN  10.244.6.8   65.86 KiB  32           15.9%             3d36c96e-f2f5-4e8a-84 \baf-34ccae43ac93  seed\r\n"]
[2278.845777, "o", "UN  10.244.2.8   65.86 KiB  32           10.5%             843b69aa-6b4b-4af6-ae \ba5-d9592af84c05  rack-1\r\n"]
[2278.847786, "o", "UN  10.244.6.9   65.86 KiB  32           18.8%             d0bf0377-f64c-4aca-8f \b25-8ac7ede0cf51  seed\r\n"]
[2278.850303, "o", "UN  10.244.5.9   65.86 KiB  32           14.5%             1f3c8795-c0cf-4b1a-be \b:\u001b[K"]
[2282.009941, "o", "\r\u001b[Kb6-96e0475c6b90  rack-3\r\nUN  10.244.5.10  65.87 KiB  32           15.4%             e3338668-96c8-4393-9b \b9e-613c8ea3ffd8  rack-3\r\nDatacenter: dataCenter-2\r\n========================\r\nStatus=Up/Down\r\n|/ State=Normal/Leaving/Joining/Moving\r\n--  Address      Load       Tokens       Owns (effective)  Host ID               \b                 Rack\r\nUN  10.244.7.4   70.81 KiB  32           14.6%             3b34cddc-f695-4741-a1 \bfe-ffceb0cf75ad  seed\r\nUN  10.244.4.5   65.86 KiB  32           15.8%             69ccfd8c-bb60-4ccc-a3 \bc5-2394d15bf677  rack-1\r\nUN  10.244.1.6   70.95 KiB  32           19.5%             9cbc2dc3-8b2a-4f16-8d \bf8-9f27e2869021  rack-1\r\n\r\n\u001b[7m(END)\u001b[27m\u001b[K"]
[2284.976034, "o", "\r\u001b[K \u001b[K:\b:"]
[2285.085432, "o", "\u001b[Kq\bq\r\u001b[K\u001b[?1l\u001b>\u001b[?1049l\u001b]0;~/src/k8s/cassandra\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~/src/k8s/cassandra\u001b[0m\r\r\n$ "]
[2286.077913, "o", "kubectl exec cluster-1-datacenter-2-rack-1-0 -n cassandra -- nodetool status|mo\rore"]
[2286.593984, "o", "\b"]
[2287.091469, "o", "\b"]
[2287.122867, "o", "\r"]
[2287.155976, "o", "\u001b[A\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C"]
[2287.189491, "o", "\b"]
[2287.220849, "o", "\b"]
[2287.25482, "o", "\b"]
[2287.286902, "o", "\b"]
[2287.320374, "o", "\b"]
[2287.354409, "o", "\b"]
[2287.386908, "o", "\b"]
[2287.41881, "o", "\b"]
[2287.452533, "o", "\b"]
[2287.484945, "o", "\b"]
[2287.519776, "o", "\b"]
[2287.551338, "o", "\b"]
[2287.583876, "o", "\b"]
[2287.617883, "o", "\b"]
[2287.650306, "o", "\b"]
[2287.683372, "o", "\b"]
[2287.718402, "o", "\b"]
[2287.749135, "o", "\b"]
[2287.782983, "o", "\b"]
[2287.816424, "o", "\b"]
[2287.848479, "o", "\b"]
[2287.880813, "o", "\b"]
[2287.915431, "o", "\b"]
[2287.946957, "o", "\b"]
[2287.980236, "o", "\b"]
[2288.013279, "o", "\b"]
[2288.046949, "o", "\b"]
[2288.080682, "o", "\b"]
[2288.112463, "o", "\b"]
[2288.14482, "o", "\b"]
[2288.178359, "o", "\b"]
[2288.212023, "o", "\b"]
[2288.244987, "o", "\b"]
[2288.276668, "o", "\b"]
[2288.31134, "o", "\b"]
[2288.346222, "o", "\b"]
[2288.375397, "o", "\b"]
[2288.408774, "o", "\b"]
[2288.672004, "o", "\b"]
[2288.83704, "o", "\b"]
[2288.992435, "o", "\b"]
[2289.165523, "o", "\b"]
[2289.992419, "o", "\b-rack-1-0 -n cassandra -- nodetool status|mor\u001b[1Pe\u001b[A\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C"]
[2290.403135, "o", "1-rack-1-0 -n cassandra -- nodetool status|more\u001b[A\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C"]
[2292.190287, "o", "\r\n\r\r\n"]
[2292.191565, "o", "\u001b[?1049h\u001b[?1h\u001b=\r"]
[2301.439346, "o", "Datacenter: dataCenter-1\r\n"]
[2301.441908, "o", "========================\r\n"]
[2301.442956, "o", "Status=Up/Down\r\n|/ State=Normal/Leaving/Joining/Moving\r\n"]
[2301.446022, "o", "--  Address      Load       Tokens       Owns (effective)  Host ID               \b"]
[2301.447046, "o", "                 Rack\r\n"]
[2301.453022, "o", "UN  10.244.3.5   65.86 KiB  32           16.6%             fe147c5f-89ec-4d3e-a9 \bba-6212b0f8b7b4  rack-1\r\n"]
[2301.540524, "o", "UN  10.244.8.6   70.95 KiB  32           14.7%             17370602-38ce-4c37-98 \b9f-7c983d5214e9  rack-2\r\n"]
[2301.541189, "o", "UN  10.244.3.6   65.86 KiB  32           12.4%             644238e9-2f4a-43e0-86 \b92-6b82cf451340  rack-1\r\n"]
[2301.546149, "o", "UN  10.244.8.7   65.86 KiB  32           13.7%             ec09aac1-2ad4-4943-88 \b0c-75efaf4cb298  rack-2\r\n"]
[2301.549658, "o", "UN  10.244.2.7   65.85 KiB  32           17.4%             8a34d5c8-c4cc-4ee2-80 \bf5-cca8c31636a2  rack-1\r\n"]
[2301.636923, "o", "UN  10.244.6.8   65.86 KiB  32           15.9%             3d36c96e-f2f5-4e8a-84 \baf-34ccae43ac93  seed\r\n"]
[2301.640028, "o", "UN  10.244.2.8   65.86 KiB  32           10.5%             843b69aa-6b4b-4af6-ae \ba5-d9592af84c05  rack-1\r\n"]
[2301.64294, "o", "UN  10.244.6.9   65.86 KiB  32           18.8%             d0bf0377-f64c-4aca-8f \b25-8ac7ede0cf51  seed\r\n"]
[2301.645648, "o", "UN  10.244.5.9   65.86 KiB  32           14.5%             1f3c8795-c0cf-4b1a-be \b:\u001b[K"]
[2303.048155, "o", "\r\u001b[K"]
[2303.048588, "o", "b6-96e0475c6b90  rack-3\r\nUN  10.244.5.10  65.87 KiB  32           15.4%             e3338668-96c8-4393-9b \b9e-613c8ea3ffd8  rack-3\r\nDatacenter: dataCenter-2\r\n========================\r\nStatus=Up/Down\r\n|/ State=Normal/Leaving/Joining/Moving\r\n--  Address      Load       Tokens       Owns (effective)  Host ID               \b                 Rack\r\nUN  10.244.7.4   70.81 KiB  32           14.6%             3b34cddc-f695-4741-a1 \bfe-ffceb0cf75ad  seed\r\nUN  10.244.4.5   65.86 KiB  32           15.8%             69ccfd8c-bb60-4ccc-a3 \bc5-2394d15bf677  rack-1\r\nUN  10.244.1.6   70.95 KiB  32           19.5%             9cbc2dc3-8b2a-4f16-8d \bf8-9f27e2869021  rack-1\r\n\r\n\u001b[7m(END)\u001b[27m\u001b[K"]
[2305.198489, "o", "\r\u001b[K \u001b[K:\b:"]
[2305.278368, "o", "\u001b[Kq\bq\r\u001b[K\u001b[?1l\u001b>\u001b[?1049l"]
[2305.279704, "o", "\u001b]0;~/src/k8s/cassandra\u0007\r\r\n\u001b[32mcloud@kubeadm-dind-cluster \u001b[35m\u001b[0m \u001b[33m~/src/k8s/cassandra\u001b[0m\r\r\n$ "]
[2308.453619, "o", "e"]
[2308.688264, "o", "x"]
[2308.97397, "o", "i"]
[2309.102448, "o", "t"]
[2309.979007, "o", "\r\nlogout\r\n"]
[2309.982508, "o", "Connection to 84.39.39.111 closed.\r\r\n\u001b]0;attu7372@ubuntu-2: ~\u0007attu7372@ubuntu-2:~$ "]
[2311.580384, "o", "exit\r\n"]
